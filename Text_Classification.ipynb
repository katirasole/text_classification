{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e345398c1da4d4a870290e479092821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51b1f690bdac481eaa90107874f33936",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6cade15c2aca4f4ba1db107aef5391b8",
              "IPY_MODEL_3eb093848f8b4cdfb6c43161e26c1057"
            ]
          }
        },
        "51b1f690bdac481eaa90107874f33936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6cade15c2aca4f4ba1db107aef5391b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fa2a4342b4384f588d78b09ac491702a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 251003,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 251003,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8031cbd355c461fbd18a80f8e5854ff"
          }
        },
        "3eb093848f8b4cdfb6c43161e26c1057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4acb748788464165bb3c01486662c1fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 251k/251k [00:05&lt;00:00, 46.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65f5e5f3843442da9800bea390c2540c"
          }
        },
        "fa2a4342b4384f588d78b09ac491702a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8031cbd355c461fbd18a80f8e5854ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4acb748788464165bb3c01486662c1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65f5e5f3843442da9800bea390c2540c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b66b2706a48e4922b031790abe237f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9620abe5f10f4d5d86493365ee40c7bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4793f99516e417594f12230a2d53d58",
              "IPY_MODEL_08a96b131e9643c4a1b2cbf6b69b10a4"
            ]
          }
        },
        "9620abe5f10f4d5d86493365ee40c7bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4793f99516e417594f12230a2d53d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a982270898a4d4e92aeba9a77c51030",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 60,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 60,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_437060dc506c440891886c97a0564716"
          }
        },
        "08a96b131e9643c4a1b2cbf6b69b10a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f03dc83b52347bab4f04219fe9f4b52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 60.0/60.0 [00:00&lt;00:00, 61.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d24d087e7784079a348aa56fa0f68ee"
          }
        },
        "6a982270898a4d4e92aeba9a77c51030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "437060dc506c440891886c97a0564716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f03dc83b52347bab4f04219fe9f4b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d24d087e7784079a348aa56fa0f68ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4bf78d37e4342cf9615567cb40bc2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1bbeba7e6331421ba3ec1ec2aedd6c11",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5fcea36921384c12b94c703ef8018f0b",
              "IPY_MODEL_d80078dbfa22418ea5942a61be24c95b"
            ]
          }
        },
        "1bbeba7e6331421ba3ec1ec2aedd6c11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fcea36921384c12b94c703ef8018f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5da85ae134a2401f91b4e6ad908ebd24",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 385,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 385,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d0a09499d6d45bea25c6f4f6f9d87e1"
          }
        },
        "d80078dbfa22418ea5942a61be24c95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8da5b550a7e4420a800ce379394bf880",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 385/385 [01:02&lt;00:00, 6.16B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f9e03ac8a184ab091e97a3da7c81ab0"
          }
        },
        "5da85ae134a2401f91b4e6ad908ebd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d0a09499d6d45bea25c6f4f6f9d87e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8da5b550a7e4420a800ce379394bf880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f9e03ac8a184ab091e97a3da7c81ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55a542df6c024211aacbbd01dad6510f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0cb1a95e80354a2ea42e6239e5c198fe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_676b936c89ea40508d0c5f9bb0fad28b",
              "IPY_MODEL_565a9e313a564478b9602620bbe2becf"
            ]
          }
        },
        "0cb1a95e80354a2ea42e6239e5c198fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "676b936c89ea40508d0c5f9bb0fad28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_02107bd4b3214714abbe9c83fca28d34",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445018508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445018508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6afc3bcf50ce4950b8fc6b76c5c38bba"
          }
        },
        "565a9e313a564478b9602620bbe2becf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c87a7de4f6e948629b1a772e37319f38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:40&lt;00:00, 10.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8443c93f9fc44ad3a9e164a126f644ef"
          }
        },
        "02107bd4b3214714abbe9c83fca28d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6afc3bcf50ce4950b8fc6b76c5c38bba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c87a7de4f6e948629b1a772e37319f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8443c93f9fc44ad3a9e164a126f644ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katirasole/text_classification/blob/main/Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# Text Classification\n",
        "\n",
        "By Katira Soleymanzadeh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJR6t_gCQe_x"
      },
      "source": [
        "In this notebook, BERT pre-trained model for Turkish [1] is utilized and is fine-tunedfor text classification task. To accomplish this task, the Huggingface library is used [2].\n",
        "\n",
        "[1] https://github.com/stefan-it/turkish-bert\n",
        "\n",
        "[2] https://huggingface.co/dbmdz/bert-base-turkish-cased \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NocWPHTVL6ub"
      },
      "source": [
        "#Install requirements and Import libraries\n",
        "\n",
        "Install required packages first and then import necessary libraries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "outputId": "278a991f-b9b8-4f6d-8433-80830d5e3101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 25.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 32.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 21.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 20.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 20.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 22.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 18.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 16.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 18.0MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 16.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 16.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 122kB 16.8MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 16.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 16.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 174kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 184kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 204kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 215kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 225kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 245kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 256kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 276kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 286kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 296kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 307kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 317kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 327kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 337kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 348kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 358kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 368kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 378kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 389kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 409kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 419kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 430kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 440kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 450kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 460kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 471kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 481kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 491kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 501kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 512kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 522kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 532kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 542kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 552kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 563kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 573kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 583kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 593kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 604kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 614kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 624kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 634kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 645kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 655kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 665kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 675kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 686kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 696kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 706kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 716kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 727kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 737kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 747kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 757kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 768kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 778kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 788kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 798kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 808kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 819kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 829kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 839kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 849kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 860kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 870kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 880kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 890kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 901kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 911kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 921kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 931kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 942kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 952kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 962kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 972kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 983kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 993kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.0MB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.0MB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 16.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 15.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 46.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=b423cd66176cf77d600965a6a525c128e5124112198078063af18d8a5ad2e24a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4ycfk1kL6Lb",
        "outputId": "f2350f1f-9820-440a-edd8-1cd411c6bd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# encoding=utf-8\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "import random\n",
        "import datetime\n",
        "import operator\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#add \"tl\" to nltk's stopword list in turkish\n",
        "all_stopwords = stopwords.words('turkish')\n",
        "all_stopwords.append('tl')\n",
        "nltk.download('punkt')\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import (BertForSequenceClassification, \n",
        "                          BertTokenizer, \n",
        "                          AdamW, \n",
        "                          BertConfig, \n",
        "                          get_linear_schedule_with_warmup,\n",
        "                         )\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## Using Colab GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "To use Google Colab GPU, you can enable it as follows:\n",
        "\n",
        "Runtime 🡒 Change runtime type\n",
        "\n",
        "then a window will open and you can use GPU or TPU. \n",
        "\n",
        "![111.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "outputId": "ad7f8512-2402-496e-a96f-95fc72eb7435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Check the available GPU and use it if it is exist. Otherwise use CPU\n",
        "if torch.cuda.is_available():        \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('CPU is exist.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# Download Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ZKxKc04Btk"
      },
      "source": [
        "Clone the github repository and mount the google drive to access the data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEVJSUfJEYj-",
        "outputId": "6c9ea643-a23a-4254-9986-cfbb973d4dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "if not os.path.exists('./text_classification'):\n",
        "    print(\"---Cloning the repo start---\")\n",
        "    !git clone https://github.com/katirasole/text_classification.git\n",
        "else:\n",
        "    print(\"---The repo is already exist---\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Cloning the repo start---\n",
            "Cloning into 'text_classification'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 61 (delta 22), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNBpoe7CEh9Q",
        "outputId": "0f09046d-9207-4407-8009-29a750659892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IFdBcbPEk3V",
        "outputId": "968516e0-1d95-46a8-e9f2-06ab18e40c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls text_classification/data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_complaint_data_90k.csv  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## Pre-Processing Data\n",
        "\n",
        "To pre-process the data the following steps are done:\n",
        "\n",
        "\n",
        "*   Do lowercase\n",
        "*   Remove numbers\n",
        "\n",
        "*   Remove punctuations\n",
        "*   Remove Turkish stop words \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Split the data into train and test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Mq5GmNeed_"
      },
      "source": [
        "def normalize_text(text):\n",
        "\n",
        "    #do lowercase \n",
        "    result_lower = ''.join((text.lower()))\n",
        "    #remove numbers\n",
        "    result_non_numeric = ''.join([i for i in result_lower if not i.isdigit()])\n",
        "    #remove punctuations\n",
        "    result_non_punc = re.sub(r\"[*'`,”+;,_,’^#@<=>~&$€%[:!\\-\\\"\\\\\\/}{?\\,.()[\\]{|}]\",'',result_non_numeric).strip()\n",
        "    #remove whitespace\n",
        "    result_non_space = re.sub(' +',' ',result_non_punc)\n",
        "    \n",
        "    #remove stopwords\n",
        "    text_tokens = word_tokenize(result_non_space)\n",
        "    tokens_without_stopword = [word for word in text_tokens if not word in all_stopwords]\n",
        "    filtered_text = (\" \").join(tokens_without_stopword)\n",
        "    \n",
        "    return (filtered_text)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sE1FQB0PRfh",
        "outputId": "eccbab19-1451-4d01-ad63-16159b9b2cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# read the dataset and then split into train and test data\n",
        "filename = ('./text_classification/data/sample_complaint_data_90k.csv')\n",
        "data = pd.read_csv(filename)\n",
        "\n",
        "#=================================Split train/test/dev ============================\n",
        "xTrain, xTest = train_test_split(data, test_size = 0.1, random_state = 0)\n",
        "\n",
        "#--------------------write train/test/dev---------------------------------\n",
        "\n",
        "def write (data, path):\n",
        "    print(\"---Writing starts---\") \n",
        "    text = data.text.values\n",
        "\n",
        "    #normalize text\n",
        "    filtered_text = []\n",
        "    for seq in text:\n",
        "        filtered_text.append(normalize_text(seq))\n",
        "        \n",
        "    category = data.category.values\n",
        "    row_data = {'text':filtered_text, 'category':category}\n",
        "\n",
        "    df = pd.DataFrame(row_data, columns = ['text', 'category'])\n",
        "    df.to_csv(path)\n",
        "    print(\"---Writing ends---\") \n",
        "    return \n",
        "\n",
        "# Write the files if there are not exist \n",
        "if not os.path.exists('./text_classification/data/train.csv' and './text_classification/data/test.csv'):\n",
        "    writeFileTrain = ('./text_classification/data/train.csv')\n",
        "    writeFileTest = ('./text_classification/data/test.csv')\n",
        "    write(xTrain, writeFileTrain)\n",
        "    write(xTest, writeFileTest)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Writing starts---\n",
            "---Writing ends---\n",
            "---Writing starts---\n",
            "---Writing ends---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vNeMXHGLtog",
        "outputId": "a1652303-203c-4f51-dc39-634f48382eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# ----------Data-------------    \n",
        "data_dir = \"./text_classification/data/\"\n",
        "\n",
        "train_file = (data_dir + 'train.csv')\n",
        "test_file = (data_dir + 'test.csv')\n",
        "\n",
        "print(\"---Read data---\")\n",
        "#-----------------train file-------------------------\n",
        "train_data = pd.read_csv(train_file)\n",
        "\n",
        "train_text = train_data.text.values\n",
        "train_category = train_data.category.values\n",
        "\n",
        "#-----------------test file-------------------------\n",
        "test_data = pd.read_csv(test_file)\n",
        "\n",
        "test_text = test_data.text.values\n",
        "test_category = test_data.category.values\n",
        "\n",
        "print(\"---Complete reading data---\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Read data---\n",
            "---Complete reading data---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7EI0ZP1NoNK",
        "outputId": "1b4cf1ee-3751-4866-d4ba-dd542ff38b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "# Convert non-numeric labels to numeric labels. \n",
        "categories = ('hesap','iade', 'iptal','kredi', 'kredi-karti', 'musteri-hizmetleri')\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "def numeric_category(train_category, test_category):\n",
        "    categories_df = pd.DataFrame(categories, columns=['category'])\n",
        "    categories_df['labels'] = le.fit_transform(categories_df['category'])\n",
        "    le.fit(train_category)\n",
        "    le.fit(test_category)\n",
        "    train_labels = le.transform(train_category)\n",
        "    test_labels = le.transform(test_category)\n",
        "    return train_labels, test_labels, categories_df\n",
        "\n",
        "train_labels, test_labels, categories_df = numeric_category(train_category, test_category)\n",
        "\n",
        "print(\"Convert non-numeric labels to numeric labels\\n\")\n",
        "print(categories_df.sort_values(by='category', ascending=True))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Convert non-numeric labels to numeric labels\n",
            "\n",
            "             category  labels\n",
            "0               hesap       0\n",
            "1                iade       1\n",
            "2               iptal       2\n",
            "3               kredi       3\n",
            "4         kredi-karti       4\n",
            "5  musteri-hizmetleri       5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpwW67IITQn4"
      },
      "source": [
        "# Text Tokenization\n",
        "\n",
        "Text Tokenization with BERT tokenizer. BERT model add special tokenes [CLS] and [SEP] to the begin and end of sequence.\n",
        "Specify the maximum sequence length of the dataset to pad or truncate the sequence.\n",
        "\n",
        "Pre-trained BERT models for Turkish:\n",
        "\n",
        "*   dbmdz/bert-base-turkish-128k-uncased\n",
        "*   dbmdz/bert-base-turkish-128k-cased\n",
        "*   dbmdz/bert-base-turkish-uncased\n",
        "*   dbmdz/bert-base-turkish-cased\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YN0IBdrVO9-",
        "outputId": "e9d1b8a1-cbe9-433f-c8a4-063c0870e25e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "7e345398c1da4d4a870290e479092821",
            "51b1f690bdac481eaa90107874f33936",
            "6cade15c2aca4f4ba1db107aef5391b8",
            "3eb093848f8b4cdfb6c43161e26c1057",
            "fa2a4342b4384f588d78b09ac491702a",
            "e8031cbd355c461fbd18a80f8e5854ff",
            "4acb748788464165bb3c01486662c1fe",
            "65f5e5f3843442da9800bea390c2540c",
            "b66b2706a48e4922b031790abe237f3b",
            "9620abe5f10f4d5d86493365ee40c7bc",
            "d4793f99516e417594f12230a2d53d58",
            "08a96b131e9643c4a1b2cbf6b69b10a4",
            "6a982270898a4d4e92aeba9a77c51030",
            "437060dc506c440891886c97a0564716",
            "0f03dc83b52347bab4f04219fe9f4b52",
            "5d24d087e7784079a348aa56fa0f68ee"
          ]
        }
      },
      "source": [
        "#Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")   "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e345398c1da4d4a870290e479092821",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=251003.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b66b2706a48e4922b031790abe237f3b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=60.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QirXVZadTPfp",
        "outputId": "aa2427a4-6743-4011-a7d4-51338811496a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "#Specify maximum sequence length to pad or truncate\n",
        "max_len = 0\n",
        "\n",
        "for seq in train_text:\n",
        "    # Tokenize the text by BERT tokenizer\n",
        "    input_ids = tokenizer.encode(seq, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sequence length    ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max sequence length     854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efvsm2XnYBex"
      },
      "source": [
        "Using tokenizer.encode_plus to get the following items:\n",
        "\n",
        "*   WordPiece based text tokenization\n",
        "*   Add [CLS] and [SEP] special tokens to the begin and the end of sequence\n",
        "*   Mapping tokens to their IDs\n",
        "*   Pad or truncate the sequence to the maximum length\n",
        "*   Prepare attantion masks for [PAD] tokens\n",
        "*   Truncation to truncate sequence to a specified maximum length\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkPK60-EXoqM"
      },
      "source": [
        "# Tokenize all of the sequences and map the tokens to thier IDs.\n",
        "input_ids_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "# For every sequences\n",
        "for seq in train_text:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        seq,                             # Sequence to encode\n",
        "                        add_special_tokens = True,       # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,                \n",
        "                        padding = 'max_length',          # Pad and truncate\n",
        "                        truncation=True,                 #Truncate the seq\n",
        "                        return_attention_mask = True,    # Construct attn. masks\n",
        "                        return_tensors = 'pt',           # Return pytorch tensors\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sequences to the list    \n",
        "    input_ids_train.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask\n",
        "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "train_labels = torch.tensor(train_labels)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqnlJjDlmCn0"
      },
      "source": [
        "Split train data to use 90% as trian and 10% as  validation set in the model training phase\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAnPp1Lvl250",
        "outputId": "3aa75a31-33bd-49ce-dd9d-1570a0119efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Change to TensorDataset and Split to train and validation sets (90-10)\n",
        "dataset = TensorDataset(input_ids_train, attention_masks_train, train_labels) \n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('training set', format(train_size))\n",
        "print('validation set', format(val_size))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 72900\n",
            "validation set 8100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOkCsSRD90eb"
      },
      "source": [
        "#Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isPv3nCj79Bs"
      },
      "source": [
        "Specify batch size. In fine-tuning BERT model the recommended batch size is 16 or 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO9MAIk97xOK"
      },
      "source": [
        "#specify batch size\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,sampler = RandomSampler(train_dataset), batch_size = batch_size)\n",
        "validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbGUXcTk-JR5"
      },
      "source": [
        "Use BertForSequenceClassification for the task. Load pre-trained BERT model for Turkish \"dbmdz/bert-base-turkish-cased\". Specify the number of categories exist in dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0qobXoq8ilc",
        "outputId": "ccbdab16-004a-4e92-880a-de7e1c122d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e4bf78d37e4342cf9615567cb40bc2c9",
            "1bbeba7e6331421ba3ec1ec2aedd6c11",
            "5fcea36921384c12b94c703ef8018f0b",
            "d80078dbfa22418ea5942a61be24c95b",
            "5da85ae134a2401f91b4e6ad908ebd24",
            "7d0a09499d6d45bea25c6f4f6f9d87e1",
            "8da5b550a7e4420a800ce379394bf880",
            "9f9e03ac8a184ab091e97a3da7c81ab0",
            "55a542df6c024211aacbbd01dad6510f",
            "0cb1a95e80354a2ea42e6239e5c198fe",
            "676b936c89ea40508d0c5f9bb0fad28b",
            "565a9e313a564478b9602620bbe2becf",
            "02107bd4b3214714abbe9c83fca28d34",
            "6afc3bcf50ce4950b8fc6b76c5c38bba",
            "c87a7de4f6e948629b1a772e37319f38",
            "8443c93f9fc44ad3a9e164a126f644ef"
          ]
        }
      },
      "source": [
        "#Specify Classification model\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dbmdz/bert-base-turkish-cased\", \n",
        "    num_labels = 6,                 \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# Run the model on GPU\n",
        "model.cuda()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4bf78d37e4342cf9615567cb40bc2c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55a542df6c024211aacbbd01dad6510f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445018508.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZIau6o1-zxm"
      },
      "source": [
        "#Specify the optimizer and epoch number\n",
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)\n",
        "\n",
        "epochs = 2    # recomende 2-4 by BERT model's authors\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mgrxAfA_x_T"
      },
      "source": [
        "Define functions to calculate the accuracy of predictions vs true labels and elapsed time as hh:mm:ss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxdtK1SD_Sri"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFrm5zGBPDOs"
      },
      "source": [
        "#Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W1K31pwAFXI",
        "outputId": "18f10345-afbe-4943-d66a-55676c05617f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "# Traing start\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "#use training_status to store loss values, accuracy and elapsed time\n",
        "training_status = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    #-------------------Training-----------------------\n",
        "    print('Epoch {:} / {:}'.format(epoch_i + 1, epochs))\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 200 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()       \n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)             \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\" Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\" Training epcoh took: {:}\".format(training_time))\n",
        "         \n",
        "    # ------------------Validation--------------------\n",
        "    print(\"\\n\")\n",
        "    print(\"Validation\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    training_status.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 / 2\n",
            "  Batch   200  of  2,279.    Elapsed: 0:02:33.\n",
            "  Batch   400  of  2,279.    Elapsed: 0:05:05.\n",
            "  Batch   600  of  2,279.    Elapsed: 0:07:38.\n",
            "  Batch   800  of  2,279.    Elapsed: 0:10:11.\n",
            "  Batch 1,000  of  2,279.    Elapsed: 0:12:44.\n",
            "  Batch 1,200  of  2,279.    Elapsed: 0:15:16.\n",
            "  Batch 1,400  of  2,279.    Elapsed: 0:17:49.\n",
            "  Batch 1,600  of  2,279.    Elapsed: 0:20:22.\n",
            "  Batch 1,800  of  2,279.    Elapsed: 0:22:55.\n",
            "  Batch 2,000  of  2,279.    Elapsed: 0:25:28.\n",
            "  Batch 2,200  of  2,279.    Elapsed: 0:28:00.\n",
            "\n",
            "\n",
            " Average training loss: 0.42\n",
            " Training epcoh took: 0:29:00\n",
            "\n",
            "\n",
            "Validation\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.38\n",
            "  Validation took: 0:01:02\n",
            "Epoch 2 / 2\n",
            "  Batch   200  of  2,279.    Elapsed: 0:02:33.\n",
            "  Batch   400  of  2,279.    Elapsed: 0:05:05.\n",
            "  Batch   600  of  2,279.    Elapsed: 0:07:38.\n",
            "  Batch   800  of  2,279.    Elapsed: 0:10:11.\n",
            "  Batch 1,000  of  2,279.    Elapsed: 0:12:44.\n",
            "  Batch 1,200  of  2,279.    Elapsed: 0:15:17.\n",
            "  Batch 1,400  of  2,279.    Elapsed: 0:17:50.\n",
            "  Batch 1,600  of  2,279.    Elapsed: 0:20:23.\n",
            "  Batch 1,800  of  2,279.    Elapsed: 0:22:56.\n",
            "  Batch 2,000  of  2,279.    Elapsed: 0:25:29.\n",
            "  Batch 2,200  of  2,279.    Elapsed: 0:28:02.\n",
            "\n",
            "\n",
            " Average training loss: 0.36\n",
            " Training epcoh took: 0:29:02\n",
            "\n",
            "\n",
            "Validation\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.36\n",
            "  Validation took: 0:01:02\n",
            "\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:00:06 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_MZTGsxGzii"
      },
      "source": [
        "#Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhZgOIC0GzPP"
      },
      "source": [
        "# Tokenize all of the sequences and map the tokens to thier IDs.\n",
        "input_ids_test = []\n",
        "attention_masks_test = []\n",
        "\n",
        "# For every sequences\n",
        "for seq in test_text:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        seq,                             # Sequence to encode\n",
        "                        add_special_tokens = True,       # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,                \n",
        "                        padding = 'max_length',          # Pad and truncate\n",
        "                        truncation=True,                 #Truncate the seq\n",
        "                        return_attention_mask = True,    # Construct attn. masks\n",
        "                        return_tensors = 'pt',           # Return pytorch tensors\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sequences to the list    \n",
        "    input_ids_test.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask\n",
        "    attention_masks_test.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
        "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDvmh4y6HYSe"
      },
      "source": [
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids_test, attention_masks_test, test_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkvHoHUmHf52",
        "outputId": "2786aa98-dcee-40cb-990f-619843d757df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences'.format(len(input_ids_test)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()    \n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 9,000 test sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxmit4w2JG4K"
      },
      "source": [
        "#Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My6qZIaBH-py"
      },
      "source": [
        "true_labels_array, result_label, result_prob, result_logits = [], [], [], []\n",
        "for j in range(len(true_labels)):\n",
        "    for i in range(len(true_labels[j])):\n",
        "        true_labels_array.append(true_labels[j][i])\n",
        "\n",
        "\n",
        "for j in range(len(predictions)):\n",
        "    for i in range(len(predictions[j])):      \n",
        "        index, value = max(enumerate(predictions[j][i]), key=operator.itemgetter(1))\n",
        "        result_label.append(index)\n",
        "        result_prob.append(value)\n",
        "        result_logits.append(predictions[j][i])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YogbVnnnMWLv",
        "outputId": "100e1269-283b-49cc-a996-6fb07e6973e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "target_names = ['hesap','iade', 'iptal','kredi', 'kredi-karti', 'musteri-hizmetleri']\n",
        "\n",
        "print(\"Accuracy     \", accuracy_score(test_labels, result_label))\n",
        "print(\"Precision    \", precision_score(test_labels, result_label, average=\"macro\"))\n",
        "print(\"Recall       \", recall_score(test_labels, result_label, average='macro'))\n",
        "print(\"F1           \", f1_score(test_labels, result_label, average=\"macro\"))\n",
        "print(classification_report(true_labels_array, result_label, target_names=target_names))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy      0.8537777777777777\n",
            "Precision     0.8546746431317914\n",
            "Recall        0.8536804135237186\n",
            "F1            0.853839777338847\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "             hesap       0.87      0.81      0.84      1512\n",
            "              iade       0.81      0.83      0.82      1497\n",
            "             iptal       0.88      0.89      0.88      1495\n",
            "             kredi       0.89      0.90      0.89      1530\n",
            "       kredi-karti       0.79      0.83      0.81      1487\n",
            "musteri-hizmetleri       0.89      0.86      0.88      1479\n",
            "\n",
            "          accuracy                           0.85      9000\n",
            "         macro avg       0.85      0.85      0.85      9000\n",
            "      weighted avg       0.85      0.85      0.85      9000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hlKdtdJOuJH"
      },
      "source": [
        "#Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry-Vcm91OT2I",
        "outputId": "51215fcd-b2e3-4af1-954a-f35399cdf7a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "output_dir = './text_classification/model_save/'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model \n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./text_classification/model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./text_classification/model_save/vocab.txt',\n",
              " './text_classification/model_save/special_tokens_map.json',\n",
              " './text_classification/model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaS4CqWeJpt_"
      },
      "source": [
        "#Predict a new complaint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j3L6noPQ581"
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "output_dir = './text_classification/model_save/'\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihW023-dJo5j",
        "outputId": "296a8c8c-9746-43c7-d458-20dad4caa9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "complaint = \"Yaklaşık 3 yıldan bu yana Akbank ile çalışmaktayım. 19/11/2013 tarihinde erken kapattığım araç kredisi için 2450 TL komisyon alınmış. 10/11/2013 tarihinde 5457 ile biten kredi kartımdan 85 TL üyelik ücreti kesilmiş.Nerede kaldı güven? Reklamlarda güvenmemiz isteniyor. Şöyle iyi banka böyle iyi banka. Komisyon alınmasın demiyoruz.Bunun da makul bir seviyesi vardır. Kesilen tutarların iadesini talep etmekteyim.\"\n",
        "complaint = normalize_text(complaint)\n",
        "print(complaint)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yaklaşık yıldan yana akbank çalışmaktayım tarihinde erken kapattığım araç kredisi komisyon alınmış tarihinde biten kredi kartımdan üyelik ücreti kesilmişnerede kaldı güven reklamlarda güvenmemiz isteniyor şöyle iyi banka böyle iyi banka komisyon alınmasın demiyoruzbunun makul bir seviyesi vardır kesilen tutarların iadesini talep etmekteyim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxNCMh1DKQGd"
      },
      "source": [
        "# Tokenize all of the sequences and map the tokens to thier IDs.\n",
        "input_ids_new = []\n",
        "attention_masks_new = []\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "                    complaint,                             # Sequence to encode\n",
        "                    add_special_tokens = True,       # Add '[CLS]' and '[SEP]'\n",
        "                    max_length = 128,                \n",
        "                    padding = 'max_length',          # Pad and truncate\n",
        "                    truncation=True,                 #Truncate the seq\n",
        "                    return_attention_mask = True,    # Construct attn. masks\n",
        "                    return_tensors = 'pt',           # Return pytorch tensors\n",
        "                )\n",
        "    \n",
        "# Add the encoded sequences to the list    \n",
        "input_ids_new.append(encoded_dict['input_ids'])\n",
        "\n",
        "# And its attention mask\n",
        "attention_masks_new.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "input_ids_new = torch.cat(input_ids_new, dim=0)\n",
        "attention_masks_new = torch.cat(attention_masks_new, dim=0)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98-hHULVKqkA",
        "outputId": "367d516d-891d-45f7-de7d-2877f0d4ae59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Prediction on test set\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids_new, token_type_ids=None, attention_mask=attention_masks_new)\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy() \n",
        "    predictions = logits[0].tolist() \n",
        "\n",
        "print(\"The predicted category is:\")\n",
        "print(target_names[predictions.index(max(predictions))])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted category is:\n",
            "kredi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7WTdaqIRN0E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}